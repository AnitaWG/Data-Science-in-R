cm[1,1]/(cm[1,1]+cm[1,2]) # coverage
cm[1,1]/(cm[1,1]+cm[2,1]) # sensitivity
table(out$y)
out <- read.delim(
"E:/baiduyun/dropbox/2014_cyou_predict_model/online/out.txt",
na.strings="NULL", stringsAsFactors=FALSE)
summary(out)
View(out)
out[ out$cn=='cn',]
out <- out[ out$cn!='cn',]
summary(out)
out$logy[ is.na(out$logy) ] <- 0
summary(out)
out$pd1 <- ifelse( out$pesm >0.5, 1, 0 ) # esm better than bagging
out$y <- ifelse( out$logy >=4, 1, 0)
table(out$y)
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pbg >0.5, 1, 0 ) # esm better than bagging
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( (out$pbg/2+out$pesm/2) >0.5, 1, 0 ) # esm better than bagging
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pesm >0.5, 1, 0 ) # esm better than bagging
table(out$y)
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pesm >0.6, 1, 0 ) # esm better than bagging
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pesm >0.7, 1, 0 ) # esm better than bagging
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pesm >0.4, 1, 0 ) # esm better than bagging
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pesm >0.3, 1, 0 ) # esm better than bagging
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pesm >0.1, 1, 0 ) # esm better than bagging
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pesm >0.3, 1, 0 ) # esm better than bagging
# out$pd1 <- ifelse( (out$pbg/2+out$pesm/2) >0.5, 1, 0 ) #
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
out$pd1 <- ifelse( out$pesm >0.1, 1, 0 ) # esm better than bagging
cm <- table( out$pd1, out$y );cm
cm[1,1]/(cm[1,1]+cm[1,2]) #
cm[1,1]/(cm[1,1]+cm[2,1]) #
install.packages("caret")
library(caret);library(kernlab);data(spam)
install.packages("kernlab")
library(caret);library(kernlab);data(spam)
head(spam)
View(spam)
inTrain <- createDataPartition( y = spam$type, p=0.75, list=F)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
set.seed(32343)
modelFit <- train(type ~., data=training, method="glm")
modelFit
modelFit$finalModel
predictions <- predict(modelFit, newdata=testing)
confusionMatrix( predictions, testing$type)
set.seed(32323)
folds <- createFolds( y= spam$type, k=10, list=T, returnTrain=T)
folds
sapply( folds, length)
folds <- createFolds( y= spam$type, k=10, list=F, returnTrain=T)
summary(folds)
table(folds)
folds <- createFolds( y= spam$type, k=10, list=F, returnTrain=F)
table(folds)
names(folds)
str(folds)
folds <- createFolds( y= spam$type, k=10, list=T, returnTrain=T)
str(folds)
folds <- createFolds( y= spam$type, k=10, list=F, returnTrain=T)
str(folds)
folds <- createFolds( y= spam$type, k=10, list=F, returnTrain=T)
str(folds)
folds <- createFolds( y= spam$type, k=10, list=F, returnTrain=F)
str(folds)
table(folds)
folds <- createFolds( y= spam$type, k=10, list=F, returnTrain=T)
table(folds)
??createFolds
folds <- createFolds( y= spam$type, k=10, list=T, returnTrain=T)
str(folds)
folds <- createFolds( y= spam$type, k=10, list=T, returnTrain=F)
str(folds)
folds <- createFolds( y= spam$type, k=10, list=T, returnTrain=T)
sapply( folds, length)
folds <- createResample( y= spam$type, times=10, list=T )
sapply( folds, length)
folds[[1]][1:10]
args(train, defualt)
args(train, default)
args(train)
??caret::train
??trainControl
library(ISLR)
install.packages("ISLR")
library(ISLR);library(ggplot2)
library(ISLR);library(ggplot2);library(caret)
data(Wage)
summary(Wage)
summary(Wage)
data(Wage)
summary(Wage)
featurePlot( x=training[,c("age","education","jobclass")],
y=train$wag, plot="pairs")
inTrain <- createDataPartition( y=Wage$wage, p=0.7, list=F )
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
featurePlot( x=training[,c("age","education","jobclass")],
y=train$wag, plot="pairs")
featurePlot( x=training[,c("age","education","jobclass")],
y=train$wage, plot="pairs")
featurePlot( x=training[,c("age","education","jobclass")],
y=training$wage, plot="pairs")
qplot( age, wage, data = training)
qplot( age, wage, color=jobclass, data = training)
qq <- qplot( age, wage, color=education, data = training)
qq + geom_smooth( method='lm', formula=y~x )
qplot(wage, color=education, data=traning, geom="density")
qplot(wage, color=education, data=training, geom="density")
rm( ls())
rm( ls(all))
rm( ls=all)
rm( all=ls())
rm( rm=ls())
rm( ls())
rm(list=ls())
library(caret);library(kernlab);data(spam)
head(spam)
# split the data into train and test
inTrain <- createDataPartition( y = spam$type, p=0.75, list=F)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
hist( training$capitalAve, main="",xlab"ave, capital run length")
training$capitalAve
hist( training$capitalAve, main="",xlab="ave, capital run length")
mean( training$capitalAve);sd( training$capitalAve )
tranCapAve <-  training$capitalAve
trainCapAveS <-  (tranCapAve - mean(tranCapAve))/sd(tranCapAve)
testCapAve <- testing@capitalAve
testCapAve <- testing@capitalAve
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve -  mean(tranCapAve))/sd(tranCapAve)
preObj <- preProcess( training[,-58], method=c("BoxCox"))
trainCapAveS <- predict(preObj, training[,-58])
trainCapAveS <- predict(preObj, training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
par(mfrow=c(1,1))
library(ISLR);library(ggplot2);library(caret)
data(Wage)
summary(Wage)
inTrain <- createDataPartition( y = Wage$wage, p=0.75, list=F)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
table(trainings$jobclass)
table(training$jobclass)
dummies <- dummyVars( wage ~ jobclass, data= training)
head( predict(dummies, newdata= training))
nsv <- nearZeroVar( training, saveMetrics=T )
library(splines)
bsBasis <- bs(training$age, df=3 )
bsBasis
rm(list=ls())
library(caret);library(kernlab);data(spam)
inTrain <- createDataPartition( y = spam$type, p=0.75, list=F)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
M <- abs( cor(training[,-58]))
diag(M) <- 0
which( M > 0.8, arr.ind= T )
which( M > 0.8, arr.ind= T )
names(spam)[c(34,32)]
plot( spam[,34] , spam[,32])
smallSpam <- spam[ , c(34,32)]
prComp <- prcomp( smallSpam)
plot( prComp$x[,1], prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type =="spam")*1 + 1 )
typeColor <- ((spam$type =="spam")*1 + 1 )
prComp <- prcomp( log10(spam[,-58]+1 )) # in case log(0) == -inf
plot( prcomp$x[,1], prComp$x[,2], col=typeColor, xlab="PC1", ylab="PC2")
plot( prComp$x[,1], prComp$x[,2], col=typeColor, xlab="PC1", ylab="PC2")
preProc <- preProcess( log10(training[,-58]+1), method="pac", pacComp=2 )
preProc <- preProcess( log10(training[,-58]+1), method="pca", pacComp=2 )
trainPc <- predict( preProc, log10(training[,-58]+1))
modelFit <- train( training$type ~ . method="glm", data =  trainPC )
modelFit <- train( training$type ~ ., method="glm", data =  trainPC )
trainPC <- predict( preProc, log10(training[,-58]+1))
modelFit <- train( training$type ~ ., method="glm", data =  trainPC )
testPC <- predict( preProc, log10( testing[, -58]+1))
confusionMatrix( testing$type, predict( modelFit, testPC ))
rm( list=ls())
library(ISLR);library(ggplot2);library(caret)
data(Wage)
data(Wage); Wage <- subset( Wage, select = -c(logwage))
summary(Wage)
inTrain <- createDataPartition( y = Wage$wage, p=0.75, list=F)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
qplot( age, wage, data=training)
qplot( age, wage, color= jobclass , data=training)
qplot( age, wage, color= education , data=training)
modFit <- train( wage~ age + jobclass + education,
method = "lm", data = training )
finMod <- modFit$finalModel
print(modFit)
data(iris)
table(iris$Species)
inTrain <- createDataPartition( y = iris$Species, p=0.75, list=F)
training <- spam[inTrain, ]
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
qplot( Petal.Width, Sepal.Width, color = Species, data= training)
modFit <- train( Species ~ . , method="rpart", data= training)
print( modFit$finalModel)
plot( modFit$finalModel, uniform=T, main="classifcation tree")
text( modFit$finalMOdel, use.n=T, all=T, cex= .8)
text( modFit$finalMOdel, use.n=T, all= T, cex= 0.8)
text( modFit$finalMOdel, use.n=T, all= T, cex= 0.8)
text( modFit$finalMOdel)
modFit$finalMOdel
modFit$finalModel
plot( modFit$finalModel, uniform=T, main="classifcation tree")
text( modFit$finalMOdel, use.n=T, all= T, cex= 0.8)
str(modFit$finalMOdel)
text( modFit$finalModel, use.n=T, all= T, cex= 0.8)
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot( modFit$finalMOdel)
fancyRpartPlot( modFit$finalModel)
library(rattle)
fancyRpartPlot( modFit$finalModel)
fancyRpartPlot( modFit$finalModel)
library(rattle)
fancyRpartPlot( modFit$finalModel)
library(rattle)
fancyRpartPlot( modFit$finalModel)
??fancyRpartPlot
fancyRpartPlot( modFit$finalModel)
library(rattle);library(rpart)
fancyRpartPlot( modFit$finalModel)
install.packages("rpart.utils")
install.packages("rpart.plot")
library(rattle);library(rpart.plot)
fancyRpartPlot( modFit$finalModel)
predict( modFit, newdata= testing )
setwd("C:\Users\dingchong\Documents\GitHub\datasciencecoursera\8.Practical Machine Learning\homework")
```
setwd("C:\Users\dingchong\Documents\GitHub\datasciencecoursera\8.Practical Machine Learning\homework")
setwd("C:/Users/dingchong/Documents/GitHub/datasciencecoursera/8.Practical Machine Learning/homework")
```
test <- read.csv("~/GitHub/datasciencecoursera/8.Practical Machine Learning/homework/pml-testing.csv", header=FALSE)
View(test)
test <- read.csv("pml-testing.csv", header= T )
View(test)
T )
train <- read.csv("pml-training.csv", header = T )
summary(train)
train <- read.csv("pml-training.csv", header = T, na.strings="#DIV/0!" )
summary(train)
test <- read.csv("pml-testing.csv", header= T , na.strings="#DIV/0!")
summary(train)
summary(train)
train <- train[,-c(1,2,3)]
train[,1]
summary( train[,1] )
length( is.na( train[,1] ))
length( is.na( train[,1] )==T)
length( train[,1]( is.na( train[,1] )))
is.na( train[,1])
is.na( train[,1]) ==T
which(is.na( train[,1]) )
train[,1]( which(is.na( train[,1]) ) )
train[,33]( which(is.na( train[,33]) ) )
summary(train)
train[,10]( which(is.na( train[,10]) ) )
which(is.na( train[,10]) )
length( which(is.na( train[,10]) ) )
summary(train)
length( which(is.na( train[,10]) ) )
nas <- vector( ncol(trian))
nas <- vector( ncol(train))
nas <- vector( length= ncol(train))
for ( i in 1: ncol(train)) {
nas[i] <- length( which(is.na( train[,10]) ) )
}
for ( i in 1: ncol(train)) {
nas[i] <- length( which(is.na( train[,i]) ) )
}
summary(nas)
nas >= nrow(train)*0.2
which( nas <= nrow(train)*0.2 )
train <- train[ , which( nas <= nrow(train)*0.2 ) ]
summary(train)
str(train)
??read.csv
train <- read.csv("pml-training.csv",
header = T, na.strings="#DIV/0!",stringsAsFactors=FALSE)
str(train)
summary(train)
train <- read.csv("pml-training.csv",
header = T, na.strings="#DIV/0!")
summary(train)
train <- train[,-c(1,2,3)]
nas <- vector( length= ncol(train))
for ( i in 1: ncol(train)) {
nas[i] <- length( which(is.na( train[,i]) ) )
}
train <- train[ , which( nas <= nrow(train)*0.2 ) ]
summary(train)
train <- read.delim("pml-training.csv",
header = T, na.strings="#DIV/0!")
train <- read.delim("pml-training.csv", sep=","
header = T, na.strings="#DIV/0!")
train <- read.delim("pml-training.csv", dec =","
header = T, na.strings="#DIV/0!")
train <- read.delim("pml-training.csv", dec =",",
header = T, na.strings="#DIV/0!")
train <- read.delim("pml-training.csv", sep =",",
header = T, na.strings="#DIV/0!")
summary(train)
train <- train[,-c(1,2,3)]
nas <- vector( length= ncol(train))
for ( i in 1: ncol(train)) {
nas[i] <- length( which(is.na( train[,i]) ) )
}
train <- train[ , which( nas <= nrow(train)*0.2 ) ]
summary(train)
nrow(train)*0.2
nas
train <- train[ , which( nas <= nrow(train)*0.2 ) ]
train <- train[ , which( nas <= nrow(train)*0.2 ) ]
which( nas <= nrow(train)*0.2 )
train <- train[ , c( which( nas <= nrow(train)*0.2 ) )]
paste( which( nas <= nrow(train)*0.2 )
)
train <- train[ , which( nas <= nrow(train)*0.2 ) ]
which( nas <= nrow(train)*0.2 )
a <- which( nas <= nrow(train)*0.2 )
train <- train[ , as.numeric(a)]
as.numeric(a)
as.numeric(a)
train <- train[ , as.numeric(a)]
train <- read.delim("pml-training.csv", sep =",", header = T, na.strings="#DIV/0!")
train <- train[,-c(1,2,3)]
nas <- vector( length= ncol(train))
for ( i in 1: ncol(train)) {
nas[i] <- length( which(is.na( train[,i]) ) )
}
a <- which( nas <= nrow(train)*0.2 )
train1 <- train[ , as.numeric(a)]
summary(train1)
str(train1[,9])
train <- read.csv("pml-training.csv",
header = T, na.strings="#DIV/0!" ,colClasses=rep("numeric", 3:16) )
rep("numeric", 3:16)
train <- read.csv("pml-training.csv",
header = T, na.strings="#DIV/0!" ,colClasses=rep("numeric", 1:160) )
train <- read.csv("pml-training.csv",
header = T, na.strings="#DIV/0!" ,colClasses=rep("numeric", 160) )
train <- read.csv("pml-training.csv",
header = T, na.strings="#DIV/0!" ,colClasses=c(NA,NA,NA, rep("numeric", 157) )
)
train <- read.delim("pml-training.csv", sep =",", header = T, na.strings="#DIV/0!")
summary(train)
nas <- vector( length= ncol(train))
for ( i in 1: ncol(train)) {
nas[i] <- length( which(is.na( train[,i]) ) )
}
a <- which( nas <= nrow(train)*0.2 )
train1 <- train[ , as.numeric(a)]
summary(train1)
names(train1)[9]
names(train1)[10]
names(train1)[12]
class(train1)[12]
is.na(train1[,12])
head( train1[,12])
names(train)
train1 <- sapply( train, as.numeric)
for ( i in 8:159) {
train[, i] <- as.numeric(train[,i])
}
rm(train1)
names(train)
summary(train)
test <- read.csv("pml-testing.csv", header= T , na.strings="#DIV/0!")
nas <- vector( length= ncol(train))
for ( i in 1: ncol(train)) {
nas[i] <- length( which(is.na( train[,i]) ) )
}
a <- which( nas <= nrow(train)*0.2 )
train <- train[ , as.numeric(a)]
summary(train)
train <- read.delim("pml-training.csv", sep =",", header = T, na.strings="#DIV/0!")
for ( i in 8:159) {
train[, i] <- as.numeric(train[,i])
}
View(train)
summary(train)
for ( i in 8:159) {
train[, i] <- as.numeric(train[,i])
}
nas <- vector( length= ncol(train))
for ( i in 1: ncol(train)) {
nas[i] <- length( which(is.na( train[,i]) ) )
}
a <- which( nas <= nrow(train)*0.2 )
train <- train[ , as.numeric(a)]
summary(train)
rm(a, i, nas)
summary(train)
class(train$classe)
library(caret)
inTrain <- createDataPartition( y = train$classe, p=0.6, list=F)
training <- train[inTrain, ]
testing <- iris[-inTrain, ]
inTest <- createDataPartition( y = testing$classe, p=0.5, list=F)
testing <- iris[-inTrain, ]
inTrain <- createDataPartition( y = train$classe, p=0.6, list=F)
training <- train[inTrain, ]
testing <- iris[-inTrain, ]
testing <- train[-inTrain, ]
inTest <- createDataPartition( y = testing$classe, p=0.5, list=F)
cv <- testing[ inTest, ]
test <- testing[ -inTest, ]
fore <- read.csv("pml-testing.csv", header= T , na.strings="#DIV/0!")
set.seed(111)
inTrain <- createDataPartition( y = train$classe, p=0.6, list=F)
training <- train[inTrain, ]
testing <- train[-inTrain, ]
inTest <- createDataPartition( y = testing$classe, p=0.5, list=F)
cv <- testing[ inTest, ]
test <- testing[ -inTest, ]
rm(inTest, inTrain, testing, train)
summary(training)
save.image("~/GitHub/datasciencecoursera/8.Practical Machine Learning/homework/data.RData")
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn); data( ozone, package="ElemStatLearn")
ozone <- ozone[ order(ozone$ozone), ]
library(ElemStatLearn); data( ozone, package="ElemStatLearn")
ozone <- ozone[ order(ozone$ozone), ]
head(ozone)
head(ozone)
ll <- matrix(NA, nrow=10, ncol= 155 )
for ( i in 1:10 ) {
ss <- sample( 1: dim(ozone)[1], replace = T )
ozone0 <- ozone[ss, ]; ozone0 <- ozone0[ order(ozone0$ozone), ]
loess0 <- loess( temperature ~ ozone, data = ozone0, span = 0.2 )
ll[i, ] <- predict( loess0, newdata=data.frame(ozone=1:155))
}
plot( ozone$ozone, ozone$temperature, pch=19, cex=0.5 )
for ( i in 1:10 ) { lines(1:155, ll[i,], col="grey", lwd=2)}
lines(1:155, apply(ll, 2, mean), col = "red", lwd =2)
predictors = data.frame(ozone=ozone$ozone)
treebag <- bag( predictors, temperature, B =10,
bagControl = bagControl( fit= ctreeBag$fit,
predict = ctreeBag$pred,
aggregate= ctreeBag$aggregate))
temperature = ozone$temperature
treebag <- bag( predictors, temperature, B =10,
bagControl = bagControl( fit= ctreeBag$fit,
predict = ctreeBag$pred,
aggregate= ctreeBag$aggregate))
library(caret)
treebag <- bag( predictors, temperature, B =10,
bagControl = bagControl( fit= ctreeBag$fit,
predict = ctreeBag$pred,
aggregate= ctreeBag$aggregate))
library(caret);library(rpart)
treebag <- bag( predictors, temperature, B =10,
bagControl = bagControl( fit= ctreeBag$fit,
predict = ctreeBag$pred,
aggregate= ctreeBag$aggregate))
data(iris);library(ggolot2)
data(iris);library(ggplot2)
inTrain <- createDataPartition( y= iris$Species, p=0.7, list=F )
training <- iris[ inTrain, ]
testing <- iris[ -inTrain, ]
rm(list=ls())
data(iris);library(ggplot2)
inTrain <- createDataPartition( y= iris$Species, p=0.7, list=F )
training <- iris[ inTrain, ]
testing <- iris[ -inTrain, ]
library(caret)
library(caret)
modFit <- train(Species~., data= training, method ="rf", prox=T )
modFit
getTree( modFit$finalModel, k= 2 )
